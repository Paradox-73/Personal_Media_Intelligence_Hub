(content_rec) E:\Personal_Media_Intelligence_Hub>python src/model_trainer.py
--- Starting Model Training for Game ---

--- Starting data loading for Game ---
Successfully loaded data\games_data.csv
Initial DataFrame info for Game:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 53 entries, 0 to 52
Data columns (total 15 columns):
 #   Column              Non-Null Count  Dtype
---  ------              --------------  -----
 0   name                53 non-null     object
 1   my_rating           53 non-null     float64
 2   platform_from_text  53 non-null     object
 3   released            52 non-null     object
 4   age_rating          42 non-null     object
 5   genres              53 non-null     object
 6   developers          52 non-null     object
 7   publishers          51 non-null     object
 8   metacritic          36 non-null     float64
 9   rating              53 non-null     float64
 10  ratings_count       53 non-null     int64
 11  reviews_count       53 non-null     int64
 12  cover               53 non-null     object
 13  tags                49 non-null     object
 14  description_raw     51 non-null     object
dtypes: float64(3), int64(2), object(10)
memory usage: 6.3+ KB

Initial DataFrame head for Game:
                          name  my_rating  ...                                               tags                                    description_raw
0  Need For Speed: Most Wanted        5.0  ...                    race, police, speed, car, racer  Wake up to the smell of burnt asphalt as the s...    
1                God of War II        5.0  ...  War, Story, console, Mythology, history, murde...  The second installment in the God of War franc...    
2                 God of War I        5.0  ...  Atmospheric, Story Rich, Hack and Slash, Blood...  Unleash the power of the Gods and embark on a ...    
3   WWE Smackdown vs. RAW 2009        4.0  ...                          friends, fun, match, demo  In WWE, the only person you can rely on, other...    
4                      FIFA 09        3.0  ...                                                NaN  Step onto the pitch and play professional foot...    

[5 rows x 15 columns]
Columns renamed: {'name': 'title', 'description_raw': 'description', 'genres': 'genres', 'cover': 'image_url', 'my_rating': 'my_rating', 'released': 'release_date'}
Converted 'release_date' to datetime and extracted 'release_year'.
Imputed missing values in 'metacritic' (from original 'metacritic') with median: 82.0
Filled missing values in 'tags' (from original 'tags') with 'Unknown'.
Filled missing values in 'description' (from original 'description_raw') with 'Unknown'.
Filled missing values in 'publishers' (from original 'publishers') with 'Unknown'.
Filled missing values in 'platform_from_text' (from original 'platform_from_text') with 'Unknown'.
Filled missing values in 'title' (from original 'name') with 'Unknown'.
Filled missing values in 'age_rating' (from original 'age_rating') with 'Unknown'.
Filled missing values in 'developers' (from original 'developers') with 'Unknown'.
Created 'like_dislike' target based on 'my_rating' >= 4.0.

DataFrame info after cleaning for Game:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 53 entries, 0 to 52
Data columns (total 17 columns):
 #   Column              Non-Null Count  Dtype
---  ------              --------------  -----
 0   title               53 non-null     object
 1   my_rating           53 non-null     float64
 2   platform_from_text  53 non-null     object
 3   release_date        52 non-null     datetime64[ns]
 4   age_rating          53 non-null     object
 5   genres              53 non-null     object
 6   developers          53 non-null     object
 7   publishers          53 non-null     object
 8   metacritic          53 non-null     float64
 9   rating              53 non-null     float64
 10  ratings_count       53 non-null     int64
 11  reviews_count       53 non-null     int64
 12  image_url           53 non-null     object
 13  tags                53 non-null     object
 14  description         53 non-null     object
 15  release_year        52 non-null     float64
 16  like_dislike        53 non-null     int64
dtypes: datetime64[ns](1), float64(4), int64(3), object(9)
memory usage: 7.2+ KB

DataFrame head after cleaning for Game:
                         title  my_rating platform_from_text  ...                                        description release_year like_dislike
0  Need For Speed: Most Wanted        5.0                PS2  ...  Wake up to the smell of burnt asphalt as the s...       2005.0            1
1                God of War II        5.0                PS2  ...  The second installment in the God of War franc...       2007.0            1
2                 God of War I        5.0                PS2  ...  Unleash the power of the Gods and embark on a ...       2005.0            1
3   WWE Smackdown vs. RAW 2009        4.0                PS2  ...  In WWE, the only person you can rely on, other...       2008.0            1
4                      FIFA 09        3.0                PS2  ...  Step onto the pitch and play professional foot...       2008.0            0

[5 rows x 17 columns]

Show rating distribution:
my_rating
5.0    15
3.0    15
4.0    14
2.0     5
4.5     3
1.0     1
Name: count, dtype: int64
Show like/dislike distribution:
like_dislike
1    32
0    21
Name: count, dtype: int64
Data split: Train samples = 42, Test samples = 11
Using device: cpu
--- Fitting FeatureExtractor for Game ---
Numerical features to fit: ['metacritic', 'rating', 'ratings_count', 'reviews_count']
Categorical features to fit: ['platform_from_text', 'age_rating']
Fitting ColumnTransformer...
ColumnTransformer fitted.
Loading text model: sentence-transformers/all-MiniLM-L6-v2
Loading image model: google/vit-base-patch16-224-in21k
Fitting PCA for text features...
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  7.75it/s] 

Error training model for Game: n_components=50 must be between 0 and min(n_samples, n_features)=42 with svd_solver='full'

Traceback (most recent call last):
  File "E:\Personal_Media_Intelligence_Hub\src\model_trainer.py", line 186, in <module>
    train_model(content_type, data_base_path, model_base_path)
  File "E:\Personal_Media_Intelligence_Hub\src\model_trainer.py", line 68, in train_model
    feature_extractor.fit(X_train, content_type=content_type)
  File "E:\Personal_Media_Intelligence_Hub\src\feature_extractor.py", line 209, in fit
    self.text_pca.fit(text_embeddings)
  File "E:\Personal_Media_Intelligence_Hub\content_rec\Lib\site-packages\sklearn\base.py", line 1363, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Personal_Media_Intelligence_Hub\content_rec\Lib\site-packages\sklearn\decomposition\_pca.py", line 440, in fit
    self._fit(X)
  File "E:\Personal_Media_Intelligence_Hub\content_rec\Lib\site-packages\sklearn\decomposition\_pca.py", line 540, in _fit
    return self._fit_full(X, n_components, xp, is_array_api_compliant)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Personal_Media_Intelligence_Hub\content_rec\Lib\site-packages\sklearn\decomposition\_pca.py", line 554, in _fit_full
    raise ValueError(
ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=42 with svd_solver='full'

================================================================================

--- Starting Model Training for Show ---

--- Starting data loading for Show ---
Successfully loaded data\shows_data.csv
Initial DataFrame info for Show:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 135 entries, 0 to 134
Data columns (total 21 columns):
 #   Column           Non-Null Count  Dtype
---  ------           --------------  -----
 0   title            135 non-null    object
 1   tvmaze_id        135 non-null    int64
 2   genres           133 non-null    object
 3   summary          135 non-null    object
 4   runtime          56 non-null     float64
 5   average_runtime  134 non-null    float64
 6   premiered        135 non-null    object
 7   language         134 non-null    object
 8   status           135 non-null    object
 9   network_country  135 non-null    object
 10  rating_avg       128 non-null    float64
 11  rating_count     0 non-null      float64
 12  popularity       135 non-null    int64
 13  show_type        135 non-null    object
 14  cast             126 non-null    object
 15  characters       126 non-null    object
 16  crew             116 non-null    object
 17  episode_count    135 non-null    int64
 18  my_rating        135 non-null    float64
 19  watch_count      134 non-null    float64
 20  year_watched     134 non-null    float64
dtypes: float64(7), int64(3), object(11)
memory usage: 22.3+ KB

Initial DataFrame head for Show:
                 title  tvmaze_id                genres  ... my_rating  watch_count  year_watched
0  The Big Bang Theory         66                Comedy  ...       2.0          2.0        2020.0
1   Brooklyn Nine-Nine         49   Comedy|Action|Crime  ...       4.0          2.0        2020.0
2               Gotham         11    Drama|Action|Crime  ...       3.0          1.0        2020.0
3        Young Sheldon      26020         Comedy|Family  ...       2.5          1.0        2020.0
4             The Boys      15299  Action|Fantasy|Adult  ...       4.0          1.0        2020.0

[5 rows x 21 columns]
Columns renamed: {'tvmaze_id': 'id', 'title': 'title', 'summary': 'description', 'genres': 'genres', 'my_rating': 'my_rating', 'premiered': 'release_date'}
E:\Personal_Media_Intelligence_Hub\src\data_loader.py:172: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.
  df["release_date"] = pd.to_datetime(df["release_date"], errors='coerce')
Converted 'release_date' to datetime and extracted 'release_year'.
Imputed missing values in 'runtime' (from original 'runtime') with median: 30.0
Imputed missing values in 'average_runtime' (from original 'average_runtime') with median: 39.5
Imputed missing values in 'rating_avg' (from original 'rating_avg') with median: 7.7
Imputed missing values in 'watch_count' (from original 'watch_count') with median: 1.0
Filled missing values in 'genres' (from original 'genres') with 'Unknown'.
Filled missing values in 'status' (from original 'status') with 'Unknown'.
Filled missing values in 'cast' (from original 'cast') with 'Unknown'.
Filled missing values in 'description' (from original 'summary') with 'Unknown'.
Filled missing values in 'language' (from original 'language') with 'Unknown'.
Filled missing values in 'show_type' (from original 'show_type') with 'Unknown'.
Filled missing values in 'crew' (from original 'crew') with 'Unknown'.
Filled missing values in 'characters' (from original 'characters') with 'Unknown'.
Filled missing values in 'title' (from original 'title') with 'Unknown'.
Created 'like_dislike' target based on 'my_rating' >= 4.0.

DataFrame info after cleaning for Show:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 135 entries, 0 to 134
Data columns (total 23 columns):
 #   Column           Non-Null Count  Dtype
---  ------           --------------  -----
 0   title            135 non-null    object
 1   id               135 non-null    int64
 2   genres           135 non-null    object
 3   description      135 non-null    object
 4   runtime          135 non-null    float64
 5   average_runtime  135 non-null    float64
 6   release_date     135 non-null    datetime64[ns]
 7   language         135 non-null    object
 8   status           135 non-null    object
 9   network_country  135 non-null    object
 10  rating_avg       135 non-null    float64
 11  rating_count     0 non-null      float64
 12  popularity       135 non-null    int64
 13  show_type        135 non-null    object
 14  cast             135 non-null    object
 15  characters       135 non-null    object
 16  crew             135 non-null    object
 17  episode_count    135 non-null    int64
 18  my_rating        135 non-null    float64
 19  watch_count      135 non-null    float64
 20  year_watched     134 non-null    float64
 21  release_year     135 non-null    int32
 22  like_dislike     135 non-null    int64
dtypes: datetime64[ns](1), float64(7), int32(1), int64(4), object(10)
memory usage: 23.9+ KB

DataFrame head after cleaning for Show:
                 title     id                genres  ... year_watched  release_year  like_dislike
0  The Big Bang Theory     66                Comedy  ...       2020.0          2007             0
1   Brooklyn Nine-Nine     49   Comedy|Action|Crime  ...       2020.0          2013             1
2               Gotham     11    Drama|Action|Crime  ...       2020.0          2014             0
3        Young Sheldon  26020         Comedy|Family  ...       2020.0          2017             0
4             The Boys  15299  Action|Fantasy|Adult  ...       2020.0          2019             1

[5 rows x 23 columns]

Show rating distribution:
my_rating
3.0    36
4.0    32
4.5    15
5.0    15
1.0    13
2.0    10
3.5     8
2.5     6
Name: count, dtype: int64
Show like/dislike distribution:
like_dislike
0    73
1    62
Name: count, dtype: int64
Data split: Train samples = 108, Test samples = 27
Using device: cpu
--- Fitting FeatureExtractor for Show ---
Numerical features to fit: ['runtime', 'average_runtime', 'rating_avg', 'popularity', 'watch_count', 'episode_count']
Categorical features to fit: ['language', 'status', 'show_type']
Fitting ColumnTransformer...
ColumnTransformer fitted.
Loading text model: sentence-transformers/all-MiniLM-L6-v2
Loading image model: google/vit-base-patch16-224-in21k
Fitting PCA for text features...
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.84it/s] 
Text PCA fitted.
FeatureExtractor fitting complete.
Transforming training data...
--- Transforming data using FeatureExtractor ---
ColumnTransformer output shape (on cpu): torch.Size([108, 16])
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.81it/s] 
Text embeddings shape (on cpu): torch.Size([108, 50])
Combined features shape (on cpu): torch.Size([108, 66])
Transforming test data...
--- Transforming data using FeatureExtractor ---
ColumnTransformer output shape (on cpu): torch.Size([27, 16])
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.58it/s] 
Text embeddings shape (on cpu): torch.Size([27, 50])
Combined features shape (on cpu): torch.Size([27, 66])
Training XGBoost Regressor model...
CUDA available. Attempting to use GPU for XGBoost training with 'gpu_hist' tree method.
XGBoost model training complete.

--- Evaluating Model ---
Mean Absolute Error (MAE): 0.8347
Root Mean Squared Error (RMSE): 1.0369
R-squared (R2): 0.3146

--- Saving trained model and feature extractor to E:\Personal_Media_Intelligence_Hub\src\..\models\show ---

Ensured directory exists: E:\Personal_Media_Intelligence_Hub\src\..\models\show
Ensured directory exists: E:\Personal_Media_Intelligence_Hub\src\..\diagnostics\show
Ensured directory exists: E:\Personal_Media_Intelligence_Hub\src\..\models\show\feature_extractor
Saving FeatureExtractor components to E:\Personal_Media_Intelligence_Hub\src\..\models\show\feature_extractor...
FeatureExtractor components saved.
Saved feature importance plot to E:\Personal_Media_Intelligence_Hub\src\..\diagnostics\show\Show_feature_importance.png
Training process complete for Show

Successfully trained model for Show.


================================================================================

--- Starting Model Training for Movie ---

--- Starting data loading for Movie ---
Successfully loaded data\movies_data.csv
Initial DataFrame info for Movie:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 368 entries, 0 to 367
Data columns (total 28 columns):
 #   Column                  Non-Null Count  Dtype
---  ------                  --------------  -----
 0   imdb_id                 368 non-null    object
 1   title                   366 non-null    object
 2   year                    366 non-null    float64
 3   rated                   357 non-null    object
 4   released                366 non-null    object
 5   runtime                 362 non-null    object
 6   genre                   364 non-null    object
 7   director                359 non-null    object
 8   writer                  358 non-null    object
 9   actors                  364 non-null    object
 10  parsed_cast             364 non-null    object
 11  parsed_crew             360 non-null    object
 12  plot                    360 non-null    object
 13  language                364 non-null    object
 14  country                 364 non-null    object
 15  awards                  350 non-null    object
 16  poster                  361 non-null    object
 17  my_rating               368 non-null    float64
 18  imdb_rating             361 non-null    float64
 19  imdb_votes              362 non-null    object
 20  metascore               355 non-null    float64
 21  rotten_tomatoes_rating  352 non-null    object
 22  type                    366 non-null    object
 23  dvd_release             4 non-null      object
 24  box_office              352 non-null    object
 25  production              2 non-null      object
 26  website                 0 non-null      float64
 27  letterboxd_name         368 non-null    object
dtypes: float64(5), object(23)
memory usage: 80.6+ KB

Initial DataFrame head for Movie:
      imdb_id           title    year  rated   released  runtime  ...   type dvd_release    box_office production website letterboxd_name
0  tt15239678  Dune: Part Two  2024.0  PG-13  01-Mar-24  166 min  ...  movie         NaN  $282,144,358        NaN     NaN  Dune: Part Two
1   tt1160419  Dune: Part One  2021.0  PG-13  22-Oct-21  155 min  ...  movie         NaN  $108,897,830        NaN     NaN            Dune
2  tt15398776     Oppenheimer  2023.0      R  21-Jul-23  180 min  ...  movie         NaN  $330,078,895        NaN     NaN     Oppenheimer
3   tt1517268          Barbie  2023.0  PG-13  21-Jul-23  114 min  ...  movie         NaN  $636,238,421        NaN     NaN          Barbie
4   tt0137523      Fight Club  1999.0      R  15-Oct-99  139 min  ...  movie         NaN   $37,030,102        NaN     NaN      Fight Club

[5 rows x 28 columns]
Columns renamed: {'imdb_id': 'id', 'title': 'title', 'plot': 'description', 'genre': 'genres', 'poster': 'image_url', 'my_rating': 'my_rating', 'released': 'release_date'}
E:\Personal_Media_Intelligence_Hub\src\data_loader.py:172: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  df["release_date"] = pd.to_datetime(df["release_date"], errors='coerce')
Converted 'release_date' to datetime and extracted 'release_year'.
Imputed missing values in 'year' (from original 'year') with median: 2008.0
Imputed missing values in 'imdb_rating' (from original 'imdb_rating') with median: 7.4
Imputed missing values in 'metascore' (from original 'metascore') with median: 69.0
Filled missing values in 'description' (from original 'plot') with 'Unknown'.
Filled missing values in 'actors' (from original 'actors') with 'Unknown'.
Filled missing values in 'language' (from original 'language') with 'Unknown'.
Filled missing values in 'director' (from original 'director') with 'Unknown'.
Filled missing values in 'awards' (from original 'awards') with 'Unknown'.
Filled missing values in 'writer' (from original 'writer') with 'Unknown'.
Filled missing values in 'genres' (from original 'genre') with 'Unknown'.
Filled missing values in 'rated' (from original 'rated') with 'Unknown'.
Filled missing values in 'title' (from original 'title') with 'Unknown'.
Created 'like_dislike' target based on 'my_rating' >= 4.0.

DataFrame info after cleaning for Movie:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 368 entries, 0 to 367
Data columns (total 30 columns):
 #   Column                  Non-Null Count  Dtype
---  ------                  --------------  -----
 0   id                      368 non-null    object
 1   title                   368 non-null    object
 2   year                    368 non-null    float64
 3   rated                   368 non-null    object
 4   release_date            366 non-null    datetime64[ns]
 5   runtime                 362 non-null    object
 6   genres                  368 non-null    object
 7   director                368 non-null    object
 8   writer                  368 non-null    object
 9   actors                  368 non-null    object
 10  parsed_cast             364 non-null    object
 11  parsed_crew             360 non-null    object
 12  description             368 non-null    object
 13  language                368 non-null    object
 14  country                 364 non-null    object
 15  awards                  368 non-null    object
 16  image_url               361 non-null    object
 17  my_rating               368 non-null    float64
 18  imdb_rating             368 non-null    float64
 19  imdb_votes              362 non-null    object
 20  metascore               368 non-null    float64
 21  rotten_tomatoes_rating  352 non-null    object
 22  type                    366 non-null    object
 23  dvd_release             4 non-null      object
 24  box_office              352 non-null    object
 25  production              2 non-null      object
 26  website                 0 non-null      float64
 27  letterboxd_name         368 non-null    object
 28  release_year            366 non-null    float64
 29  like_dislike            368 non-null    int64
dtypes: datetime64[ns](1), float64(6), int64(1), object(22)
memory usage: 86.4+ KB

DataFrame head after cleaning for Movie:
           id           title    year  rated release_date  runtime  ...    box_office production website letterboxd_name release_year like_dislike
0  tt15239678  Dune: Part Two  2024.0  PG-13   2024-03-01  166 min  ...  $282,144,358        NaN     NaN  Dune: Part Two       2024.0            1      
1   tt1160419  Dune: Part One  2021.0  PG-13   2021-10-22  155 min  ...  $108,897,830        NaN     NaN            Dune       2021.0            1      
2  tt15398776     Oppenheimer  2023.0      R   2023-07-21  180 min  ...  $330,078,895        NaN     NaN     Oppenheimer       2023.0            1      
3   tt1517268          Barbie  2023.0  PG-13   2023-07-21  114 min  ...  $636,238,421        NaN     NaN          Barbie       2023.0            0      
4   tt0137523      Fight Club  1999.0      R   1999-10-15  139 min  ...   $37,030,102        NaN     NaN      Fight Club       1999.0            1      

[5 rows x 30 columns]

Show rating distribution:
my_rating
4.0    152
3.0    128
5.0     38
2.0     34
1.0     10
3.5      3
2.5      3
Name: count, dtype: int64
Show like/dislike distribution:
like_dislike
1    190
0    178
Name: count, dtype: int64
Data split: Train samples = 294, Test samples = 74
Using device: cpu
--- Fitting FeatureExtractor for Movie ---
Numerical features to fit: ['year', 'imdb_rating', 'metascore']
Categorical features to fit: ['rated', 'language']
Fitting ColumnTransformer...
ColumnTransformer fitted.
Loading text model: sentence-transformers/all-MiniLM-L6-v2
Loading image model: google/vit-base-patch16-224-in21k
Fitting PCA for text features...
Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  9.61it/s] 
Text PCA fitted.
Fitting PCA for image features...
Extracting image features: 100%|█████████████████████████████████████████████████████████████████████████████████████| 294/294 [02:03<00:00,  2.37it/s] 
Image PCA fitted.
FeatureExtractor fitting complete.
Transforming training data...
--- Transforming data using FeatureExtractor ---
ColumnTransformer output shape (on cpu): torch.Size([294, 118])
Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  9.95it/s] 
Text embeddings shape (on cpu): torch.Size([294, 50])
Extracting image features: 100%|█████████████████████████████████████████████████████████████████████████████████████| 294/294 [02:00<00:00,  2.43it/s] 
Image embeddings shape (on cpu): torch.Size([294, 50])
Combined features shape (on cpu): torch.Size([294, 218])
Transforming test data...
--- Transforming data using FeatureExtractor ---
ColumnTransformer output shape (on cpu): torch.Size([74, 118])
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 10.04it/s] 
Text embeddings shape (on cpu): torch.Size([74, 50])
Extracting image features:  32%|████████████████████████████▏                                                          | 24/74 [00:08<00:18,  2.73it/s]Image download failed from https://m.media-amazon.com/images/M/MV5BM2UzYjk5MTQtY2U3NC00ODlmLTg2ZGYtMDc1N2Q5YTc0OWViXkEyXkFqcGdeQXVyMjMyMjA0NTA@._V1_SX300.jpg: 404 Client Error: Not Found for url: https://m.media-amazon.com/images/M/MV5BM2UzYjk5MTQtY2U3NC00ODlmLTg2ZGYtMDc1N2Q5YTc0OWViXkEyXkFqcGdeQXVyMjMyMjA0NTA@._V1_SX300.jpg
Extracting image features: 100%|███████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:27<00:00,  2.73it/s] 
Image embeddings shape (on cpu): torch.Size([74, 50])
Combined features shape (on cpu): torch.Size([74, 218])
Training XGBoost Regressor model...
CUDA available. Attempting to use GPU for XGBoost training with 'gpu_hist' tree method.
XGBoost model training complete.

--- Evaluating Model ---
Mean Absolute Error (MAE): 0.5445
Root Mean Squared Error (RMSE): 0.6988
R-squared (R2): 0.4022

--- Saving trained model and feature extractor to E:\Personal_Media_Intelligence_Hub\src\..\models\movie ---

Ensured directory exists: E:\Personal_Media_Intelligence_Hub\src\..\models\movie
Ensured directory exists: E:\Personal_Media_Intelligence_Hub\src\..\diagnostics\movie
Ensured directory exists: E:\Personal_Media_Intelligence_Hub\src\..\models\movie\feature_extractor
Saving FeatureExtractor components to E:\Personal_Media_Intelligence_Hub\src\..\models\movie\feature_extractor...
FeatureExtractor components saved.
Saved feature importance plot to E:\Personal_Media_Intelligence_Hub\src\..\diagnostics\movie\Movie_feature_importance.png
Training process complete for Movie

Successfully trained model for Movie.


================================================================================

--- Starting Model Training for Book ---

--- Starting data loading for Book ---
Successfully loaded data\books_data.csv
Initial DataFrame info for Book:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 59 entries, 0 to 58
Data columns (total 17 columns):
 #   Column               Non-Null Count  Dtype
---  ------               --------------  -----
 0   title                59 non-null     object
 1   my_rating            59 non-null     object
 2   authors              59 non-null     object
 3   publisher            51 non-null     object
 4   publishedDate        59 non-null     object
 5   pageCount            56 non-null     float64
 6   categories           56 non-null     object
 7   averageRating        26 non-null     float64
 8   ratingsCount         26 non-null     float64
 9   language             59 non-null     object
 10  description          55 non-null     object
 11  thumbnail            54 non-null     object
 12  previewLink          59 non-null     object
 13  infoLink             59 non-null     object
 14  retailPriceAmount    4 non-null      float64
 15  retailPriceCurrency  4 non-null      object
 16  accessViewStatus     59 non-null     object
dtypes: float64(4), object(13)
memory usage: 8.0+ KB

Initial DataFrame head for Book:
                                    title my_rating      authors  ... retailPriceAmount retailPriceCurrency  accessViewStatus
0  Diary of a Wimpy Kid 3 : The Last Stra       2.5  Jeff Kinney  ...               NaN                 NaN              NONE
1                          The Ugly Truth         3  Jeff Kinney  ...               NaN                 NaN              NONE
2                                Dog Days         3  Jeff Kinney  ...               NaN                 NaN              NONE
3                               Hard Luck       2.5  Jeff Kinney  ...               NaN                 NaN              NONE
4                           Rodrick Rules         3  Jeff Kinney  ...               NaN                 NaN              NONE

[5 rows x 17 columns]
Columns renamed: {'title': 'title', 'description': 'description', 'categories': 'genres', 'thumbnail': 'image_url', 'my_rating': 'my_rating', 'publishedDate': 'release_date'}
Converted 'release_date' to datetime and extracted 'release_year'.
Imputed missing values in 'averageRating' (from original 'averageRating') with median: 4.5
Imputed missing values in 'ratingsCount' (from original 'ratingsCount') with median: 2.0
Filled missing values in 'authors' (from original 'authors') with 'Unknown'.
Filled missing values in 'genres' (from original 'categories') with 'Unknown'.
Filled missing values in 'language' (from original 'language') with 'Unknown'.
Filled missing values in 'publisher' (from original 'publisher') with 'Unknown'.
Filled missing values in 'description' (from original 'description') with 'Unknown'.
Filled missing values in 'title' (from original 'title') with 'Unknown'.
Dropped 2 rows due to missing 'my_rating'.
Created 'like_dislike' target based on 'my_rating' >= 4.0.

DataFrame info after cleaning for Book:
<class 'pandas.core.frame.DataFrame'>
Index: 57 entries, 0 to 58
Data columns (total 19 columns):
 #   Column               Non-Null Count  Dtype
---  ------               --------------  -----
 0   title                57 non-null     object
 1   my_rating            57 non-null     float64
 2   authors              57 non-null     object
 3   publisher            57 non-null     object
 4   release_date         25 non-null     datetime64[ns]
 5   pageCount            55 non-null     float64
 6   genres               57 non-null     object
 7   averageRating        57 non-null     float64
 8   ratingsCount         57 non-null     float64
 9   language             57 non-null     object
 10  description          57 non-null     object
 11  image_url            53 non-null     object
 12  previewLink          57 non-null     object
 13  infoLink             57 non-null     object
 14  retailPriceAmount    3 non-null      float64
 15  retailPriceCurrency  3 non-null      object
 16  accessViewStatus     57 non-null     object
 17  release_year         25 non-null     float64
 18  like_dislike         57 non-null     int64
dtypes: datetime64[ns](1), float64(6), int64(1), object(11)
memory usage: 8.9+ KB

DataFrame head after cleaning for Book:
                                    title  my_rating      authors  ... accessViewStatus release_year  like_dislike
0  Diary of a Wimpy Kid 3 : The Last Stra        2.5  Jeff Kinney  ...             NONE       2009.0             0
1                          The Ugly Truth        3.0  Jeff Kinney  ...             NONE          NaN             0
2                                Dog Days        3.0  Jeff Kinney  ...             NONE          NaN             0
3                               Hard Luck        2.5  Jeff Kinney  ...             NONE          NaN             0
4                           Rodrick Rules        3.0  Jeff Kinney  ...             NONE       2009.0             0

[5 rows x 19 columns]

Show rating distribution:
my_rating
3.0    19
3.5    13
4.0     9
2.5     4
4.5     4
5.0     4
2.0     3
1.0     1
Name: count, dtype: int64
Show like/dislike distribution:
like_dislike
0    40
1    17
Name: count, dtype: int64
Data split: Train samples = 45, Test samples = 12
Using device: cpu
--- Fitting FeatureExtractor for Book ---
Numerical features to fit: ['averageRating', 'ratingsCount']
Categorical features to fit: ['language']
Fitting ColumnTransformer...
ColumnTransformer fitted.
Loading text model: sentence-transformers/all-MiniLM-L6-v2
Loading image model: google/vit-base-patch16-224-in21k
Fitting PCA for text features...
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.44it/s] 

Error training model for Book: n_components=50 must be between 0 and min(n_samples, n_features)=45 with svd_solver='full'

Traceback (most recent call last):
  File "E:\Personal_Media_Intelligence_Hub\src\model_trainer.py", line 186, in <module>
    train_model(content_type, data_base_path, model_base_path)
  File "E:\Personal_Media_Intelligence_Hub\src\model_trainer.py", line 68, in train_model
    feature_extractor.fit(X_train, content_type=content_type)
  File "E:\Personal_Media_Intelligence_Hub\src\feature_extractor.py", line 209, in fit
    self.text_pca.fit(text_embeddings)
  File "E:\Personal_Media_Intelligence_Hub\content_rec\Lib\site-packages\sklearn\base.py", line 1363, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Personal_Media_Intelligence_Hub\content_rec\Lib\site-packages\sklearn\decomposition\_pca.py", line 440, in fit
    self._fit(X)
  File "E:\Personal_Media_Intelligence_Hub\content_rec\Lib\site-packages\sklearn\decomposition\_pca.py", line 540, in _fit
    return self._fit_full(X, n_components, xp, is_array_api_compliant)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Personal_Media_Intelligence_Hub\content_rec\Lib\site-packages\sklearn\decomposition\_pca.py", line 554, in _fit_full
    raise ValueError(
ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=45 with svd_solver='full'

================================================================================

--- Starting Model Training for Music ---

--- Starting data loading for Music ---
Successfully loaded data\spotify_all_unique_tracks_combined.csv
Successfully loaded data\spotify_saved_albums.csv
Successfully loaded data\spotify_top_tracks.csv
Initial DataFrame info for Music:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 12709 entries, 0 to 12708
Data columns (total 15 columns):
 #   Column            Non-Null Count  Dtype
---  ------            --------------  -----
 0   Track Name        12607 non-null  object
 1   Artist(s)         12708 non-null  object
 2   Album Name        12708 non-null  object
 3   Playlist Name(s)  2669 non-null   object
 4   Genre(s)          7588 non-null   object
 5   Release Date      12708 non-null  object
 6   Popularity        12708 non-null  float64
 7   Track ID          12607 non-null  object
 8   Track URL         12607 non-null  object
 9   Added At          2771 non-null   object
 10  Album Type        102 non-null    object
 11  Total Tracks      102 non-null    float64
 12  Album ID          102 non-null    object
 13  Album URL         102 non-null    object
 14  Time Range        9938 non-null   object
dtypes: float64(2), object(13)
memory usage: 1.5+ MB

Initial DataFrame head for Music:
                    Track Name                       Artist(s)                Album Name Playlist Name(s)  ... Total Tracks Album ID  Album URL Time Range
0                 Ace Trumpets         Clipse, Pusha T, Malice              Ace Trumpets      Liked Songs  ...          NaN      NaN        NaN        NaN
1     WASSUP (feat. JPEGMAFIA)  Joey Valence & Brae, JPEGMAFIA  WASSUP (feat. JPEGMAFIA)      Liked Songs  ...          NaN      NaN        NaN        NaN
2                 The Contract               Twenty One Pilots              The Contract      Liked Songs  ...          NaN      NaN        NaN        NaN
3  Video Killed The Radio Star                     The Buggles        The Age Of Plastic      Liked Songs  ...          NaN      NaN        NaN        NaN
4                Dark Thoughts                       Lil Tecca             Dark Thoughts      Liked Songs  ...          NaN      NaN        NaN        NaN

[5 rows x 15 columns]
Columns renamed: {'Track ID': 'id', 'Track Name': 'title', 'Album Name': 'description', 'Genre(s)': 'genres', 'Popularity': 'my_rating', 'Release Date': 'release_date'}
Converted 'release_date' to datetime and extracted 'release_year'.
Imputed missing values in 'my_rating' (from original 'Popularity') with median: 62.0
Filled missing values in 'Artist(s)' (from original 'Artist(s)') with 'Unknown'.
Filled missing values in 'title' (from original 'Track Name') with 'Unknown'.
Filled missing values in 'description' (from original 'Album Name') with 'Unknown'.
Warning: 'Popularity' column not found for Music. Cannot derive 'my_rating'.
Created 'like_dislike' target based on 'my_rating' >= 3.0.

DataFrame info after cleaning for Music:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 12709 entries, 0 to 12708
Data columns (total 17 columns):
 #   Column            Non-Null Count  Dtype
---  ------            --------------  -----
 0   title             12709 non-null  object
 1   Artist(s)         12709 non-null  object
 2   description       12709 non-null  object
 3   Playlist Name(s)  2669 non-null   object
 4   genres            7588 non-null   object
 5   release_date      12423 non-null  datetime64[ns]
 6   my_rating         12709 non-null  float64
 7   id                12607 non-null  object
 8   Track URL         12607 non-null  object
 9   Added At          2771 non-null   object
 10  Album Type        102 non-null    object
 11  Total Tracks      102 non-null    float64
 12  Album ID          102 non-null    object
 13  Album URL         102 non-null    object
 14  Time Range        9938 non-null   object
 15  release_year      12423 non-null  float64
 16  like_dislike      12709 non-null  int64
dtypes: datetime64[ns](1), float64(3), int64(1), object(12)
memory usage: 1.6+ MB

DataFrame head after cleaning for Music:
                         title                       Artist(s)               description  ... Time Range release_year like_dislike
0                 Ace Trumpets         Clipse, Pusha T, Malice              Ace Trumpets  ...        NaN       2025.0            1
1     WASSUP (feat. JPEGMAFIA)  Joey Valence & Brae, JPEGMAFIA  WASSUP (feat. JPEGMAFIA)  ...        NaN       2025.0            1
2                 The Contract               Twenty One Pilots              The Contract  ...        NaN       2025.0            1
3  Video Killed The Radio Star                     The Buggles        The Age Of Plastic  ...        NaN       1980.0            1
4                Dark Thoughts                       Lil Tecca             Dark Thoughts  ...        NaN       2025.0            1

[5 rows x 17 columns]

Show rating distribution:
my_rating
66.0    363
61.0    317
64.0    316
60.0    314
65.0    314
       ...
7.0      12
94.0     11
9.0       9
13.0      7
98.0      2
Name: count, Length: 96, dtype: int64
Show like/dislike distribution:
like_dislike
1    12433
0      276
Name: count, dtype: int64
Data split: Train samples = 10167, Test samples = 2542
Using device: cpu
--- Fitting FeatureExtractor for Music ---
Categorical features to fit: ['Artist(s)']
Fitting ColumnTransformer...
ColumnTransformer fitted.
Loading text model: sentence-transformers/all-MiniLM-L6-v2
Loading image model: google/vit-base-patch16-224-in21k
Fitting PCA for text features...
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 318/318 [00:12<00:00, 25.96it/s]
Text PCA fitted.
FeatureExtractor fitting complete.
Transforming training data...
--- Transforming data using FeatureExtractor ---
ColumnTransformer output shape (on cpu): torch.Size([10167, 2093])
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 318/318 [00:13<00:00, 24.24it/s]
Text embeddings shape (on cpu): torch.Size([10167, 50])
Combined features shape (on cpu): torch.Size([10167, 2143])
Transforming test data...
--- Transforming data using FeatureExtractor ---
ColumnTransformer output shape (on cpu): torch.Size([2542, 2093])
Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:03<00:00, 25.15it/s]
Text embeddings shape (on cpu): torch.Size([2542, 50])
Combined features shape (on cpu): torch.Size([2542, 2143])
Training XGBoost Regressor model...
CUDA available. Attempting to use GPU for XGBoost training with 'gpu_hist' tree method.
XGBoost model training complete.

--- Evaluating Model ---
Mean Absolute Error (MAE): 9.7439
Root Mean Squared Error (RMSE): 14.0312
R-squared (R2): 0.4367

--- Saving trained model and feature extractor to E:\Personal_Media_Intelligence_Hub\src\..\models\music ---

Ensured directory exists: E:\Personal_Media_Intelligence_Hub\src\..\models\music
Ensured directory exists: E:\Personal_Media_Intelligence_Hub\src\..\diagnostics\music
Ensured directory exists: E:\Personal_Media_Intelligence_Hub\src\..\models\music\feature_extractor
Saving FeatureExtractor components to E:\Personal_Media_Intelligence_Hub\src\..\models\music\feature_extractor...
FeatureExtractor components saved.
Saved feature importance plot to E:\Personal_Media_Intelligence_Hub\src\..\diagnostics\music\Music_feature_importance.png
Training process complete for Music

Successfully trained model for Music.


================================================================================